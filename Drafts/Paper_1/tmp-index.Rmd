---
title: |
   "Life history variability influence on the recovery potential of globally exploited teleosts "
french_title: "Titre ici (*Nom latin de l'esp√®ce*)"
author: |
  David. M. Keith^1^ 
  Freya M. Keyser^1^
  Julie M. Charbonneau^2^
  Heather 'The Boss' Bowlby^1^
author_list: "Keith, D.M., Keyser, F.M., Charbonneau, J.M., Bowlby, H.T.B."
address: |
  ^1^Bedford Institute of Oceanography\
     Fisheries and Oceans Canada, 1 Challenger Dr.\
     Dartmouth, Nova Scotia, B2Y 4A2 , Canada\
  \smallskip
  ^2^Simon Fraser University\
     Department of Biology\
french_address: |
  
month: ""
french_month: ""
year: 2024
report_number: nnn
region: "Maritimes Region"
french_region: "Maritimes Region"
isbn: ""
cat_no: ""
citation_other_language: ""

abstract: |
  Here is the abstract text. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

  Start new paragraphs after a blank line and with 2 spaces indent. Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

french_abstract: |

header: "Draft working paper --- Do not cite or circulate" # or "" to omit
output:
 csasdown::resdoc_word:
   french: false
   copy_sty: true
   line_nums: true
   line_nums_mod: 1
   lot_lof: false
   draft_watermark: false
   include_section_nums: true
   highlight: tango
# ------------
# End of options to set
knit: (function(input, ...) {
       csasdown::render('_bookdown.yml')
      })
link-citations: true
bibliography: Y:/Zotero/MAR_SABHU.bib
# Any extra LaTeX code for the header:
# header-includes:
# - \usepackage{tikz}
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type <- "png"
} else {
  knitr_figs_dir <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type <- "png"
}
fig_asp <- 0.618
fig_width <- 9
fig_out_width <- "6in"
fig_dpi <- 180
fig_align <- "center"
fig_pos <- "htb"
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  #  autodep = TRUE,
  #  cache = TRUE,
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
```

```{r load-libraries-n-data, echo = FALSE, cache = FALSE, message = FALSE, results = 'hide', warning = FALSE}
# add other packages here:
library(dplyr)
library(readr)
library(tibble)
library(csasdown)
# OK, so using the ICES assessments here's what we get for North Sea cod.
library(readxl)
library(tidyverse)
library(rio)
library(ggthemes)
library(cowplot)
library(gtable)
library(viridis)
library(arm)
library(mgcv)
library(lme4)
library(scales)
library(ggh4x)
library(gratia)
theme_set(theme_few(base_size = 14))


# The location of your data
loc <- 'D:/GitHub/ICM'
# The parameters for the doubling time simulation
n.dt.sims <- 1000 # Increase to 1000 for final run, which takes like a full day or something 
n.sim.years <- 100
# If we already have the results don't re-run the models or load data we don't need.
load.results <- F
# What tunning model are you running or did you run!
what.2.tune <- 'fec_nm'

#source(paste0(loc,"/Scripts/functions/tuning_sim_fast.R"))

# Download the functions we'll need from github
funs <- c("https://raw.githubusercontent.com/dave-keith/ICM/main/Scripts/functions/simple_Lotka_r.r",
          "https://raw.githubusercontent.com/dave-keith/ICM/main/Scripts/functions/backwards_project.r",
          "https://raw.githubusercontent.com/dave-keith/ICM/main/Scripts/functions/forward_project.r",
          "https://raw.githubusercontent.com/dave-keith/ICM/main/Scripts/functions/tuning_sim_fast.r"
)
  # Now run through a quick loop to load each one, just be sure that your working directory is read/write!
for(fun in funs) 
{
  download.file(fun,destfile = basename(fun))
  source(paste0(getwd(),"/",basename(fun)))
  file.remove(paste0(getwd(),"/",basename(fun)))
}

if(load.results==F)
{
  # Choose 5 ICES stocks that we have the necessary data for
  #ASR <- read_xlsx("../Data/ASR_2018.xlsx" sheet = "ICES")
  ASR1 <- read.csv(paste0(loc,"/Data/ICM_data_NE_atlantic_stocks.csv"))
  ASR <- read.csv(paste0(loc,"/Data/ICM_data_NW_atlantic_stocks.csv"))
  
  
  
  ASR <- rbind(ASR1,ASR)
  datatypes <- unique(gsub(x = names(ASR), pattern = "[^a-zA-Z]", replacement=""))
  
  # Replace 0's in Num.tot with NA so the rest of this works as Freya designed it to...
  ASR$Num.tot[ASR$Num.tot == 0] <- NA
  # we want:
  # Year, Num, WA, Catch, AM, NM, StockID, Management, Area, Order, Family, Genus, Species
  ASRdat <- ASR[,c(grep(x=names(ASR), "Num"),
                   grep(x=names(ASR), "WA"),
                   grep(x=names(ASR), "Catch"),
                   grep(x=names(ASR), "AM"),
                   grep(x=names(ASR), "NM"))]
  # Making all the data numeric that should be numeric
  ASRdat <- apply(X = ASRdat, 2, as.numeric)
  # Getting the species info back
  ASRsp <- ASR[, which(!1:length(names(ASR)) %in% grep(x=names(ASR), ".", fixed=T))]
  # And binding it all back together
  ASR.trim <- cbind(ASRsp, ASRdat)
  # need a unique ID for stock
  #table(ASR.trim$Management, ASR.trim$Species)
  ASR.trim$Stock <- paste0(ASR.trim$Management, "_", ASR.trim$Area, "_", ASR.trim$Genus, "_", ASR.trim$Species)
  
  ASR.long <- ASR.trim %>%
    pivot_longer(!c("Management", "Area", "Order", "Family", "Genus", "Species", "Stock", "Year","Meeting_or_reference","Model","Case","Notes")) %>%
    separate(col=name, into=c("type", "age"), sep = "\\.")
  
  # Something is weird with the mentella stock, I'm going to drop it...
  ASR.long <- ASR.long %>% dplyr::filter(Stock != "ICES-AFWG_DEEP1-2_Sebastes_mentella")
}# end if load results
```

```{r bilingual-code, cache=FALSE}
options(
  # Prevent xtable from adding a timestamp comment to the table code it produces
  xtable.comment = FALSE,
  # Do not allow kableExtra to load packages, we add them manually in csasdown
  kableExtra.latex.load_packages = FALSE,
  # Stop chunk output (echo) running into the margins
  width = 80,
  # Do not use scientific notation (stops tables from showing 1.2e3, etc.)
  scipen = 999)

meta <- rmarkdown::metadata
meta_out <- rmarkdown::metadata$output
csl <- "csl/csas.csl"
options(OutDec = ".")
if (is.null(getOption("french"))) {
  stop("`french` was not set up correctly in YAML header in index.Rmd. ",
       "It must be true or false",
       call. = FALSE)
}
if (getOption("french")) {
  csl <- "csl/csas-french.csl"
  options(OutDec = ",")
}

french <- isTRUE(getOption("french")) # for backwards compatibility

# This hook simplifies document translation for the author.
# When building in French, it draws a box around paragraphs contained in chunks
#  which have the option `needs_trans = TRUE`. It also labels
#  the box with a "Needs translation" tag in red and the chunk label in blue.
# You need to change the `needs_trans` option to `FALSE` for a chunk once you
#  have inserted the translated text into it. You will get a utf-8 error if
#  you leave it as `TRUE` and there is French in the chunk.
#  This function assumes you are translating from English to French.
#  If you wrote your document in French and want to translate to English,
#  put a ! before `getOption("french")` below and add the `need_trans`
#  chunk options to your English paragraph chunks instead of the French ones.
#  
#  IMPORTANT NOTES
#  - Use `csasdown::render()` to render the document. This runs a
#    pre-processing step which ensures any inline R chunks
#    `r print("Like this one")` are taken care of correctly and that all
#    backslash variables (eg. \pi, \alpha, \@ref, \cite) are all processed
#    correctly.
#  - French latex places a space before the colon by default so if you need a colon
#    with no space before it, use \\hc .
knit_hooks$set(needs_trans = function(before, options){
  if(getOption("french") && options$needs_trans){
    if (before){
      paste0("\\
   \\begin{lrbox}{\\userinput}
   \\begin{minipage}{\\dimexpr\\linewidth-2\\fboxsep-2\\fboxrule}
   \\textcolor{red}{\\textbf{Needs translation - \\textcolor{blue}{knitr chunk: ", options$label, "}}}
   \\begin{lstlisting}
  ")
    } else {
      "
   \\end{lstlisting}
   \\end{minipage}
   \\end{lrbox}
   \\noindent
   \\fbox{\\usebox{\\userinput}}
  "
    }
  }
})
```

---
title: `r ifelse(fr(), meta$french_title, meta$title)`
month: `r ifelse(fr(), meta$french_month, meta$month)`
region: `r ifelse(fr(), meta$french_region, meta$region)`
csl: `r csl`
---
